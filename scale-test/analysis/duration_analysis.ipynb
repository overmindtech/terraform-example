{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale Test Duration Analysis\n",
    "\n",
    "Analyze correlations between run duration and various metrics (blast radius, edges, observations) to understand what drives performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "Fetch from dashboard API or use sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Fetch from Dashboard API\n",
    "DASHBOARD_URL = os.getenv('SCALE_DASHBOARD_URL', '')\n",
    "DASHBOARD_API_KEY = os.getenv('SCALE_DASHBOARD_API_KEY', '')\n",
    "\n",
    "def fetch_from_api():\n",
    "    \"\"\"Fetch run data from dashboard API.\"\"\"\n",
    "    if not DASHBOARD_URL or not DASHBOARD_API_KEY:\n",
    "        print(\"Dashboard credentials not set. Using sample data.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(\n",
    "            f\"{DASHBOARD_URL}/api/results\",\n",
    "            headers={\"Authorization\": f\"Bearer {DASHBOARD_API_KEY}\"},\n",
    "            timeout=30\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch from API: {e}\")\n",
    "        return None\n",
    "\n",
    "# Option 2: Sample data from recent runs\n",
    "SAMPLE_DATA = [\n",
    "    # Latest run data from user\n",
    "    {\"scenario\": \"kms_orphan_simulation\", \"duration_seconds\": 761, \"risk_count\": 0, \"blast_radius\": 677, \"edges\": 1972, \"observations\": 246},\n",
    "    {\"scenario\": \"combined_all\", \"duration_seconds\": 1215, \"risk_count\": 0, \"blast_radius\": 803, \"edges\": 2054, \"observations\": 304},\n",
    "    {\"scenario\": \"combined_network\", \"duration_seconds\": 1177, \"risk_count\": 1, \"blast_radius\": 749, \"edges\": 1896, \"observations\": 281},\n",
    "    {\"scenario\": \"central_sns_change\", \"duration_seconds\": 594, \"risk_count\": 1, \"blast_radius\": 719, \"edges\": 1989, \"observations\": 241},\n",
    "    {\"scenario\": \"vpc_peering_change\", \"duration_seconds\": 814, \"risk_count\": 0, \"blast_radius\": 786, \"edges\": 2108, \"observations\": 278},\n",
    "    {\"scenario\": \"lambda_timeout\", \"duration_seconds\": 1445, \"risk_count\": 0, \"blast_radius\": 1096, \"edges\": 12010, \"observations\": 408},\n",
    "    {\"scenario\": \"shared_sg_open\", \"duration_seconds\": 1457, \"risk_count\": 0, \"blast_radius\": 846, \"edges\": 1965, \"observations\": 315},\n",
    "    # Previous run data\n",
    "    {\"scenario\": \"kms_orphan_simulation\", \"duration_seconds\": 782, \"risk_count\": 0, \"blast_radius\": 768, \"edges\": 2094, \"observations\": 276},\n",
    "    {\"scenario\": \"combined_all\", \"duration_seconds\": 501, \"risk_count\": 1, \"blast_radius\": 543, \"edges\": 1853, \"observations\": 169},\n",
    "    {\"scenario\": \"combined_network\", \"duration_seconds\": 845, \"risk_count\": 1, \"blast_radius\": 722, \"edges\": 2107, \"observations\": 228},\n",
    "    {\"scenario\": \"central_sns_change\", \"duration_seconds\": 678, \"risk_count\": 0, \"blast_radius\": 598, \"edges\": 1727, \"observations\": 178},\n",
    "    {\"scenario\": \"vpc_peering_change\", \"duration_seconds\": 457, \"risk_count\": 0, \"blast_radius\": 695, \"edges\": 2091, \"observations\": 209},\n",
    "    {\"scenario\": \"lambda_timeout\", \"duration_seconds\": 776, \"risk_count\": 0, \"blast_radius\": 1053, \"edges\": 7042, \"observations\": 347},\n",
    "    {\"scenario\": \"shared_sg_open\", \"duration_seconds\": 636, \"risk_count\": 2, \"blast_radius\": 530, \"edges\": 1617, \"observations\": 186},\n",
    "]\n",
    "\n",
    "# Try API first, fall back to sample data\n",
    "api_data = fetch_from_api()\n",
    "if api_data:\n",
    "    # Transform API response to match our format\n",
    "    data = []\n",
    "    for run in api_data.get('results', api_data):\n",
    "        data.append({\n",
    "            \"scenario\": run.get('scenario'),\n",
    "            \"duration_seconds\": run.get('overmindDurationMs', 0) / 1000,\n",
    "            \"risk_count\": run.get('riskCount', 0),\n",
    "            \"blast_radius\": run.get('blastRadiusNodes', 0),\n",
    "            \"edges\": run.get('blastRadiusEdges', 0),\n",
    "            \"observations\": run.get('observations', 0),\n",
    "        })\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"Loaded {len(df)} runs from API\")\n",
    "else:\n",
    "    df = pd.DataFrame(SAMPLE_DATA)\n",
    "    print(f\"Using {len(df)} sample runs\")\n",
    "\n",
    "df['duration_minutes'] = df['duration_seconds'] / 60\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== Summary Statistics ===\")\n",
    "print(df[['duration_minutes', 'blast_radius', 'edges', 'observations']].describe())\n",
    "\n",
    "print(\"\\n=== By Scenario (mean) ===\")\n",
    "scenario_stats = df.groupby('scenario').agg({\n",
    "    'duration_minutes': ['mean', 'std', 'count'],\n",
    "    'blast_radius': 'mean',\n",
    "    'edges': 'mean',\n",
    "    'observations': 'mean'\n",
    "}).round(2)\n",
    "scenario_stats.columns = ['_'.join(col).strip() for col in scenario_stats.columns.values]\n",
    "print(scenario_stats.sort_values('duration_minutes_mean', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Correlation Analysis\n",
    "\n",
    "Which metrics are most correlated with duration?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "correlation_cols = ['duration_seconds', 'blast_radius', 'edges', 'observations', 'risk_count']\n",
    "corr_matrix = df[correlation_cols].corr()\n",
    "\n",
    "print(\"=== Correlation with Duration ===\")\n",
    "duration_corr = corr_matrix['duration_seconds'].drop('duration_seconds').sort_values(ascending=False)\n",
    "for col, corr in duration_corr.items():\n",
    "    strength = \"strong\" if abs(corr) > 0.7 else \"moderate\" if abs(corr) > 0.4 else \"weak\"\n",
    "    print(f\"  {col}: {corr:.3f} ({strength})\")\n",
    "\n",
    "# Heatmap\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.imshow(corr_matrix, cmap='RdYlBu_r', aspect='auto', vmin=-1, vmax=1)\n",
    "ax.set_xticks(range(len(correlation_cols)))\n",
    "ax.set_yticks(range(len(correlation_cols)))\n",
    "ax.set_xticklabels(correlation_cols, rotation=45, ha='right')\n",
    "ax.set_yticklabels(correlation_cols)\n",
    "plt.colorbar(im, ax=ax, label='Correlation')\n",
    "\n",
    "# Add values\n",
    "for i in range(len(correlation_cols)):\n",
    "    for j in range(len(correlation_cols)):\n",
    "        ax.text(j, i, f'{corr_matrix.iloc[i, j]:.2f}', ha='center', va='center', fontsize=10)\n",
    "\n",
    "plt.title('Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scatter Plots\n",
    "\n",
    "Visualize relationships between duration and each metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "metrics = [\n",
    "    ('blast_radius', 'Blast Radius (nodes)'),\n",
    "    ('edges', 'Edges'),\n",
    "    ('observations', 'Observations'),\n",
    "    ('risk_count', 'Risk Count')\n",
    "]\n",
    "\n",
    "# Color by scenario\n",
    "scenarios = df['scenario'].unique()\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(scenarios)))\n",
    "color_map = dict(zip(scenarios, colors))\n",
    "\n",
    "for ax, (metric, label) in zip(axes.flat, metrics):\n",
    "    for scenario in scenarios:\n",
    "        subset = df[df['scenario'] == scenario]\n",
    "        ax.scatter(subset[metric], subset['duration_minutes'], \n",
    "                   c=[color_map[scenario]], label=scenario, s=80, alpha=0.7)\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(df[metric], df['duration_minutes'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    x_line = np.linspace(df[metric].min(), df[metric].max(), 100)\n",
    "    ax.plot(x_line, p(x_line), 'r--', alpha=0.5, label='Trend')\n",
    "    \n",
    "    ax.set_xlabel(label)\n",
    "    ax.set_ylabel('Duration (minutes)')\n",
    "    ax.set_title(f'Duration vs {label}')\n",
    "\n",
    "# Add legend\n",
    "handles, labels = axes[0, 0].get_legend_handles_labels()\n",
    "fig.legend(handles[:len(scenarios)], labels[:len(scenarios)], \n",
    "           loc='center right', bbox_to_anchor=(1.15, 0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Duration Prediction Model\n",
    "\n",
    "Fit a linear model to predict duration from metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features for prediction\n",
    "features = ['blast_radius', 'edges', 'observations']\n",
    "X = df[features]\n",
    "y = df['duration_seconds']\n",
    "\n",
    "# Fit model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "print(\"=== Duration Prediction Formula ===\")\n",
    "print(f\"duration_seconds = {model.intercept_:.2f}\")\n",
    "for feat, coef in zip(features, model.coef_):\n",
    "    sign = '+' if coef >= 0 else '-'\n",
    "    print(f\"  {sign} {abs(coef):.4f} × {feat}\")\n",
    "\n",
    "print(f\"\\nR² Score: {model.score(X, y):.3f}\")\n",
    "print(\"(1.0 = perfect prediction, 0.0 = no predictive power)\")\n",
    "\n",
    "# Feature importance (standardized coefficients)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "model_scaled = LinearRegression()\n",
    "model_scaled.fit(X_scaled, y)\n",
    "\n",
    "print(\"\\n=== Feature Importance (Standardized) ===\")\n",
    "importance = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Coefficient': model_scaled.coef_,\n",
    "    'Abs Importance': np.abs(model_scaled.coef_)\n",
    "}).sort_values('Abs Importance', ascending=False)\n",
    "\n",
    "for _, row in importance.iterrows():\n",
    "    pct = row['Abs Importance'] / importance['Abs Importance'].sum() * 100\n",
    "    print(f\"  {row['Feature']}: {pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Outlier Analysis\n",
    "\n",
    "Which runs took longer or shorter than expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict duration for each run\n",
    "df['predicted_seconds'] = model.predict(X)\n",
    "df['residual'] = df['duration_seconds'] - df['predicted_seconds']\n",
    "df['residual_pct'] = (df['residual'] / df['predicted_seconds']) * 100\n",
    "\n",
    "print(\"=== Outlier Analysis ===\")\n",
    "print(\"\\nRuns SLOWER than expected (residual > 20%):\")\n",
    "slow = df[df['residual_pct'] > 20].sort_values('residual_pct', ascending=False)\n",
    "if len(slow) > 0:\n",
    "    for _, row in slow.iterrows():\n",
    "        print(f\"  {row['scenario']}: {row['duration_minutes']:.1f}m actual vs {row['predicted_seconds']/60:.1f}m expected ({row['residual_pct']:+.0f}%)\")\n",
    "else:\n",
    "    print(\"  None\")\n",
    "\n",
    "print(\"\\nRuns FASTER than expected (residual < -20%):\")\n",
    "fast = df[df['residual_pct'] < -20].sort_values('residual_pct')\n",
    "if len(fast) > 0:\n",
    "    for _, row in fast.iterrows():\n",
    "        print(f\"  {row['scenario']}: {row['duration_minutes']:.1f}m actual vs {row['predicted_seconds']/60:.1f}m expected ({row['residual_pct']:+.0f}%)\")\n",
    "else:\n",
    "    print(\"  None\")\n",
    "\n",
    "# Residual plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "colors = [color_map[s] for s in df['scenario']]\n",
    "ax.scatter(df['predicted_seconds']/60, df['residual']/60, c=colors, s=100, alpha=0.7)\n",
    "ax.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "ax.set_xlabel('Predicted Duration (minutes)')\n",
    "ax.set_ylabel('Residual (actual - predicted, minutes)')\n",
    "ax.set_title('Residual Plot: Actual vs Predicted Duration')\n",
    "\n",
    "# Annotate outliers\n",
    "for _, row in df[abs(df['residual_pct']) > 30].iterrows():\n",
    "    ax.annotate(row['scenario'], \n",
    "                (row['predicted_seconds']/60, row['residual']/60),\n",
    "                xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Efficiency Metrics\n",
    "\n",
    "Normalized metrics to compare scenarios fairly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate efficiency metrics\n",
    "df['seconds_per_node'] = df['duration_seconds'] / df['blast_radius']\n",
    "df['seconds_per_1k_edges'] = df['duration_seconds'] / (df['edges'] / 1000)\n",
    "df['seconds_per_observation'] = df['duration_seconds'] / df['observations']\n",
    "\n",
    "print(\"=== Efficiency Metrics (lower = faster) ===\")\n",
    "efficiency = df.groupby('scenario').agg({\n",
    "    'seconds_per_node': 'mean',\n",
    "    'seconds_per_1k_edges': 'mean',\n",
    "    'seconds_per_observation': 'mean',\n",
    "    'duration_minutes': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "print(efficiency.sort_values('seconds_per_1k_edges', ascending=False))\n",
    "\n",
    "# Bar chart of efficiency\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "x = np.arange(len(efficiency))\n",
    "width = 0.25\n",
    "\n",
    "ax.bar(x - width, efficiency['seconds_per_node'], width, label='sec/node')\n",
    "ax.bar(x, efficiency['seconds_per_1k_edges'], width, label='sec/1k edges')\n",
    "ax.bar(x + width, efficiency['seconds_per_observation'], width, label='sec/observation')\n",
    "\n",
    "ax.set_xlabel('Scenario')\n",
    "ax.set_ylabel('Seconds')\n",
    "ax.set_title('Efficiency Metrics by Scenario')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(efficiency.index, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"KEY INSIGHTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Top correlated metric\n",
    "top_corr = duration_corr.idxmax()\n",
    "top_corr_val = duration_corr.max()\n",
    "print(f\"\\n1. STRONGEST PREDICTOR: {top_corr}\")\n",
    "print(f\"   Correlation: {top_corr_val:.3f}\")\n",
    "print(f\"   Implication: Higher {top_corr} → longer duration\")\n",
    "\n",
    "# Model accuracy\n",
    "r2 = model.score(X, y)\n",
    "print(f\"\\n2. PREDICTION ACCURACY: {r2*100:.0f}%\")\n",
    "if r2 > 0.7:\n",
    "    print(\"   Duration is well explained by blast radius, edges, and observations.\")\n",
    "else:\n",
    "    print(\"   Other factors also significantly affect duration.\")\n",
    "\n",
    "# Slowest scenario\n",
    "slowest = scenario_stats.sort_values('duration_minutes_mean', ascending=False).iloc[0]\n",
    "print(f\"\\n3. SLOWEST SCENARIO: {slowest.name}\")\n",
    "print(f\"   Average: {slowest['duration_minutes_mean']:.1f} minutes\")\n",
    "\n",
    "# Most variable\n",
    "most_variable = scenario_stats.sort_values('duration_minutes_std', ascending=False).iloc[0]\n",
    "print(f\"\\n4. MOST VARIABLE: {most_variable.name}\")\n",
    "print(f\"   Std Dev: {most_variable['duration_minutes_std']:.1f} minutes\")\n",
    "print(f\"   (May benefit from investigation)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
