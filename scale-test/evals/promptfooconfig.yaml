# PromptFoo Quality Evaluation for Overmind Risk Analysis
# Evaluates the quality of detected risks from change-results.json

description: Overmind Risk Analysis Quality Eval

# We're evaluating existing results, not calling an LLM for generation
# The "provider" here is just for the LLM-as-judge assertions
providers:
  - id: openai:gpt-4o-mini
    config:
      temperature: 0

# Default assertions applied to all tests
defaultTest:
  options:
    # Load the change results from the file passed via --vars
    transformVars: |
      (vars) => {
        const fs = require('fs');
        const resultsPath = vars.results_file || '../change-results.json';
        try {
          const data = JSON.parse(fs.readFileSync(resultsPath, 'utf8'));
          return {
            ...vars,
            risks: data.risks || [],
            risk_count: (data.risks || []).length,
            high_risk_count: (data.risks || []).filter(r => r.severity === 'high' || r.severity === 'critical').length,
            change_data: data
          };
        } catch (e) {
          console.error('Failed to load results:', e.message);
          return { ...vars, risks: [], risk_count: 0, high_risk_count: 0, change_data: {} };
        }
      }

# The prompts section - we pass the risks as context for evaluation
prompts:
  - |
    Evaluate the quality of these infrastructure risk assessments:

    Scenario: {{scenario}}
    Expected behavior: {{expected}}

    Detected Risks:
    {{#each risks}}
    - [{{severity}}] {{title}}
      Description: {{description}}
    {{/each}}

    {{#if (eq risk_count 0)}}
    No risks were detected.
    {{/if}}

tests:
  # ===========================================================================
  # shared_sg_open: SSH open to 0.0.0.0/0
  # ===========================================================================
  - description: "shared_sg_open: Should detect critical SSH exposure risk"
    vars:
      scenario: shared_sg_open
      expected: "Should detect high/critical risk for SSH (port 22) open to 0.0.0.0/0"
    assert:
      # Must have at least one high-severity risk
      - type: javascript
        value: "vars.high_risk_count > 0"
        metric: has_high_risk
      # Should mention SSH or port 22 or security group
      - type: javascript
        value: |
          const risks = vars.risks || [];
          return risks.some(r => 
            /ssh|port.?22|security.?group|0\.0\.0\.0/i.test(r.title + ' ' + r.description)
          );
        metric: mentions_ssh
      # LLM-as-judge: Is this a good risk assessment?
      - type: llm-rubric
        value: |
          The risk assessment should clearly identify that SSH (port 22) is being 
          opened to the entire internet (0.0.0.0/0). This is a critical security 
          vulnerability. The description should explain why this is dangerous.
          Score 1 if the risks correctly identify this issue, 0 if not.
        metric: quality_score

  # ===========================================================================
  # lambda_timeout: Timeout reduced to 1 second
  # ===========================================================================
  - description: "lambda_timeout: Should detect timeout reliability risk"
    vars:
      scenario: lambda_timeout
      expected: "Should detect medium risk for Lambda timeout reduced to 1 second"
    assert:
      # Must have at least one risk
      - type: javascript
        value: "vars.risk_count > 0"
        metric: has_risk
      # Should mention timeout or Lambda or reliability
      - type: javascript
        value: |
          const risks = vars.risks || [];
          return risks.some(r => 
            /timeout|lambda|function|reliability|1.?second/i.test(r.title + ' ' + r.description)
          );
        metric: mentions_timeout
      # LLM-as-judge quality
      - type: llm-rubric
        value: |
          The risk assessment should identify that reducing a Lambda function timeout 
          to 1 second is problematic. Most Lambda operations need more than 1 second.
          This could cause widespread function failures.
          Score 1 if risks identify this reliability concern, 0 if not.
        metric: quality_score

  # ===========================================================================
  # vpc_peering_change: DNS resolution enabled
  # ===========================================================================
  - description: "vpc_peering_change: Should provide meaningful network analysis"
    vars:
      scenario: vpc_peering_change
      expected: "May or may not flag as risk - should provide thoughtful analysis"
    assert:
      # This one is ambiguous - we just check that IF risks exist, they're relevant
      - type: javascript
        value: |
          const risks = vars.risks || [];
          if (risks.length === 0) return true; // No risks is acceptable
          // If risks exist, they should mention VPC, peering, DNS, or network
          return risks.some(r => 
            /vpc|peering|dns|network|resolution|connectivity/i.test(r.title + ' ' + r.description)
          );
        metric: relevant_analysis
      # LLM-as-judge quality
      - type: llm-rubric
        value: |
          Enabling DNS resolution on VPC peering is an ambiguous change - it could be 
          necessary for cross-VPC communication or could expand attack surface.
          If risks are detected, they should be thoughtful about network implications.
          If no risks, that's also acceptable for this scenario.
          Score 1 if the analysis (or lack thereof) seems reasonable, 0 if not.
        metric: quality_score

  # ===========================================================================
  # central_sns_change: SNS topic policy modified
  # ===========================================================================
  - description: "central_sns_change: Should detect SNS policy risk"
    vars:
      scenario: central_sns_change
      expected: "Should detect risk for central SNS topic policy change"
    assert:
      - type: javascript
        value: "vars.risk_count > 0"
        metric: has_risk
      - type: javascript
        value: |
          const risks = vars.risks || [];
          return risks.some(r => 
            /sns|topic|policy|messaging|notification/i.test(r.title + ' ' + r.description)
          );
        metric: mentions_sns
      - type: llm-rubric
        value: |
          Modifying a central SNS topic policy that many services depend on is risky.
          The assessment should identify potential impact on downstream subscribers.
          Score 1 if the analysis captures the messaging/policy risk, 0 if not.
        metric: quality_score

  # ===========================================================================
  # combined_network: Multiple high-severity changes
  # ===========================================================================
  - description: "combined_network: Should detect multiple high-severity risks"
    vars:
      scenario: combined_network
      expected: "Should detect multiple high/critical risks for combined security/network changes"
    assert:
      - type: javascript
        value: "vars.high_risk_count > 0"
        metric: has_high_risk
      # Should find more than one risk for combined scenarios
      - type: javascript
        value: "vars.risk_count >= 1"
        metric: multiple_risks
      - type: llm-rubric
        value: |
          Combined network scenarios include multiple risky changes (VPC peering + 
          security group modifications). The analysis should identify multiple risks
          and their potential compound impact.
          Score 1 if multiple risks are identified with appropriate severity, 0 if not.
        metric: quality_score

  # ===========================================================================
  # GCP: shared_firewall_open
  # ===========================================================================
  - description: "shared_firewall_open: Should detect GCP firewall risk"
    vars:
      scenario: shared_firewall_open
      expected: "Should detect high/critical risk for GCP firewall open to internet"
    assert:
      - type: javascript
        value: "vars.high_risk_count > 0"
        metric: has_high_risk
      - type: javascript
        value: |
          const risks = vars.risks || [];
          return risks.some(r => 
            /firewall|ssh|port.?22|0\.0\.0\.0|internet|gcp|gce/i.test(r.title + ' ' + r.description)
          );
        metric: mentions_firewall
      - type: llm-rubric
        value: |
          Opening SSH on a GCP firewall to 0.0.0.0/0 is a critical security issue,
          similar to AWS security groups. All instances with the network tag are exposed.
          Score 1 if risks correctly identify firewall/SSH exposure, 0 if not.
        metric: quality_score
