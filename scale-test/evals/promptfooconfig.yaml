# PromptFoo Quality Evaluation for Overmind Risk Analysis
# Evaluates the quality of detected risks from change-results.json
#
# Variables passed from CI:
#   - scenario: The test scenario name (e.g., shared_sg_open)
#   - risk_count: Total number of risks detected
#   - high_risk_count: Number of high/critical severity risks
#   - risks_json: JSON array of risk objects

description: Overmind Risk Analysis Quality Eval

# We're evaluating existing results, not calling an LLM for generation
# The "provider" here is just for the LLM-as-judge assertions
providers:
  - id: openai:gpt-5
    config:
      temperature: 0

# The prompts section - we pass the risks as context for evaluation
prompts:
  - |
    Evaluate the quality of these infrastructure risk assessments:

    Scenario: {{scenario}}
    Expected behavior: {{expected}}
    
    Total risks detected: {{risk_count}}
    High/critical risks: {{high_risk_count}}
    
    Risk details (JSON): {{risks_json}}

tests:
  # ===========================================================================
  # shared_sg_open: SSH open to 0.0.0.0/0
  # ===========================================================================
  - description: "shared_sg_open: Should detect critical SSH exposure risk"
    vars:
      expected: "Should detect high/critical risk for SSH (port 22) open to 0.0.0.0/0"
    assert:
      # Must have at least one high-severity risk (severity === "high")
      - type: javascript
        value: |
          const count = parseInt(context.vars.high_risk_count);
          if (isNaN(count)) {
            console.log('high_risk_count is not a number:', context.vars.high_risk_count);
            return false;
          }
          console.log('High risk count:', count);
          return count > 0;
        metric: has_high_risk
      # Should mention SSH or port 22 or security group in the risks JSON
      - type: javascript
        value: |
          const risksJson = context.vars.risks_json;
          if (!risksJson || risksJson === '[]') {
            console.log('No risks detected');
            return false;
          }
          const risks = JSON.parse(risksJson);
          console.log('Checking', risks.length, 'risks for SSH-related keywords');
          const found = risks.some(r => 
            /ssh|port.?22|security.?group|0\.0\.0\.0/i.test((r.title || '') + ' ' + (r.description || ''))
          );
          console.log('Found SSH-related risk:', found);
          return found;
        metric: mentions_ssh
      # LLM-as-judge: Is this a good risk assessment?
      - type: llm-rubric
        value: |
          The risk assessment should clearly identify that SSH (port 22) is being 
          opened to the entire internet (0.0.0.0/0). This is a critical security 
          vulnerability. The description should explain why this is dangerous.
          Score 1 if the risks correctly identify this issue, 0 if not.
        metric: quality_score

  # ===========================================================================
  # lambda_timeout: Timeout reduced to 1 second
  # NOTE: Currently not producing expected risks due to baseline/pollution issues
  # ===========================================================================
  - description: "lambda_timeout: Should detect timeout reliability risk"
    vars:
      expected: "Should detect medium risk for Lambda timeout reduced to 1 second"
      # Ground truth: The expected risk that MUST be detected
      ground_truth_title: "Reducing Lambda timeout to 1s will terminate executions before SQS delete/S3/HTTP completes, causing retries, duplicates, DLQ traffic, and failed snapshot I/O"
      ground_truth_description: |
        Multiple Lambda functions are being reduced from a 3-second to a 1-second timeout 
        while they interact with SQS and S3. At 1 second, cold starts, network latency, 
        and normal SQS/S3/HTTP operations that previously completed in 1-3 seconds will 
        be terminated by Lambda before cleanup or DeleteMessage can occur.
        
        When these functions time out, SQS messages remain invisible until the queue's 
        VisibilityTimeout expires, then are retried, causing duplicate deliveries, backlogs, 
        and DLQ traffic. In-flight S3/HTTP calls will be aborted, surfacing as 5xx/timeouts.
      ground_truth_severity: "medium"
      ground_truth_concepts: "Lambda, timeout, 1 second, SQS, S3, retries, DLQ, function termination"
    assert:
      # Currently this scenario produces 0 risks - check if scenario is working
      - type: javascript
        value: |
          const count = parseInt(context.vars.risk_count);
          console.log('lambda_timeout risk count:', count);
          // TODO: Change to count > 0 once scenario pollution is fixed
          if (count === 0) {
            console.log('WARNING: lambda_timeout produced 0 risks - scenario may not be working');
          }
          return true;  // Pass for now, but log warning
        metric: scenario_check
      # IF risks are detected, check if they match expected pattern
      - type: javascript
        value: |
          const risksJson = context.vars.risks_json;
          if (!risksJson || risksJson === '[]') {
            console.log('lambda_timeout: No risks detected (scenario may need fixing)');
            return true;  // Pass for now - scenario not producing risks yet
          }
          const risks = JSON.parse(risksJson);
          // Check if any risk mentions timeout/lambda
          const found = risks.some(r => 
            /timeout|lambda|function/i.test((r.title || '') + ' ' + (r.description || ''))
          );
          console.log('lambda_timeout: Found timeout-related risk:', found);
          return found || risks.length === 0;  // Pass if relevant or no risks
        metric: relevant_if_present

  # ===========================================================================
  # vpc_peering_change: DNS resolution enabled
  # ===========================================================================
  - description: "vpc_peering_change: Should provide meaningful network analysis"
    vars:
      expected: "May or may not flag as risk - should provide thoughtful analysis"
    assert:
      # This one is ambiguous - we just check that IF risks exist, they're relevant
      - type: javascript
        value: |
          try {
            const risks = JSON.parse(context.vars.risks_json || '[]');
            if (risks.length === 0) return true; // No risks is acceptable
            // If risks exist, they should mention VPC, peering, DNS, or network
            return risks.some(r => 
              /vpc|peering|dns|network|resolution|connectivity/i.test((r.title || '') + ' ' + (r.description || ''))
            );
          } catch (e) { return true; }
        metric: relevant_analysis
      # LLM-as-judge quality
      - type: llm-rubric
        value: |
          Enabling DNS resolution on VPC peering is an ambiguous change - it could be 
          necessary for cross-VPC communication or could expand attack surface.
          If risks are detected, they should be thoughtful about network implications.
          If no risks, that's also acceptable for this scenario.
          Score 1 if the analysis (or lack thereof) seems reasonable, 0 if not.
        metric: quality_score

  # ===========================================================================
  # central_sns_change: SNS topic policy modified
  # NOTE: Currently not producing expected risks due to baseline/pollution issues
  # ===========================================================================
  - description: "central_sns_change: Should detect SNS policy risk"
    vars:
      expected: "Should detect risk for central SNS topic policy change"
    assert:
      # Currently this scenario produces 0 risks - check if scenario is working
      - type: javascript
        value: |
          const count = parseInt(context.vars.risk_count);
          console.log('central_sns_change risk count:', count);
          if (count === 0) {
            console.log('WARNING: central_sns_change produced 0 risks - scenario may not be working');
          }
          return true;  // Pass for now
        metric: scenario_check
      # IF risks are detected, check if they're relevant
      - type: javascript
        value: |
          const risksJson = context.vars.risks_json;
          if (!risksJson || risksJson === '[]') {
            console.log('central_sns_change: No risks detected (scenario may need fixing)');
            return true;  // Pass for now
          }
          const risks = JSON.parse(risksJson);
          const found = risks.some(r => 
            /sns|topic|policy|messaging|notification/i.test((r.title || '') + ' ' + (r.description || ''))
          );
          console.log('central_sns_change: Found SNS-related risk:', found);
          return found || risks.length === 0;
        metric: relevant_if_present

  # ===========================================================================
  # combined_network: Multiple high-severity changes
  # ===========================================================================
  - description: "combined_network: Should detect multiple high-severity risks"
    vars:
      expected: "Should detect multiple high/critical risks for combined security/network changes"
    assert:
      - type: javascript
        value: |
          const count = parseInt(context.vars.high_risk_count);
          console.log('High risk count for combined_network:', count);
          return count > 0;
        metric: has_high_risk
      # Should find at least one risk for combined scenarios
      - type: javascript
        value: |
          const count = parseInt(context.vars.risk_count);
          console.log('Total risk count for combined_network:', count);
          return count >= 1;
        metric: multiple_risks
      - type: llm-rubric
        value: |
          Combined network scenarios include multiple risky changes (VPC peering + 
          security group modifications). The analysis should identify multiple risks
          and their potential compound impact.
          Score 1 if multiple risks are identified with appropriate severity, 0 if not.
        metric: quality_score

  # ===========================================================================
  # combined_all: All AWS high-fanout scenarios combined
  # NOTE: Currently producing 1 medium risk (shared SG SSH exposure)
  # ===========================================================================
  - description: "combined_all: Should detect multiple high-severity risks"
    vars:
      expected: "Should detect risks for combined AWS changes"
    assert:
      # Must have at least one risk (high or medium)
      - type: javascript
        value: |
          const count = parseInt(context.vars.risk_count);
          console.log('combined_all total risk count:', count);
          return count > 0;
        metric: has_risk
      # Check for security-related risks
      - type: javascript
        value: |
          const risksJson = context.vars.risks_json;
          if (!risksJson || risksJson === '[]') return false;
          const risks = JSON.parse(risksJson);
          const found = risks.some(r => 
            /security|ssh|0\.0\.0\.0|ingress|expose/i.test((r.title || '') + ' ' + (r.description || ''))
          );
          console.log('combined_all: Found security-related risk:', found);
          return found;
        metric: mentions_security
      - type: llm-rubric
        value: |
          The combined_all scenario includes security group modifications. 
          The analysis should identify security risks related to SSH exposure.
          Score 1 if security risks are identified, 0 if not.
        metric: quality_score

  # ===========================================================================
  # combined_max: Maximum blast radius scenario
  # ===========================================================================
  - description: "combined_max: Should detect critical risks for max scenario"
    vars:
      expected: "Should detect critical risks including all-ports-open and Lambda timeout"
    assert:
      - type: javascript
        value: |
          const count = parseInt(context.vars.high_risk_count);
          console.log('High risk count for combined_max:', count);
          return count > 0;
        metric: has_high_risk
      - type: javascript
        value: |
          const count = parseInt(context.vars.risk_count);
          console.log('Total risk count for combined_max:', count);
          return count >= 2;
        metric: multiple_risks
      - type: llm-rubric
        value: |
          The combined_max scenario is the most severe: it opens ALL ports (0-65535) 
          instead of just SSH, modifies Lambda timeouts, and includes all other changes.
          The analysis should identify this as extremely risky with multiple critical issues.
          Score 1 if the severity is appropriately identified as critical, 0 if not.
        metric: quality_score

  # ===========================================================================
  # kms_orphan_simulation: KMS key duplication scenario
  # NOTE: Currently not producing expected risks - may need scenario adjustment
  # ===========================================================================
  - description: "kms_orphan_simulation: Should detect KMS/encryption risk"
    vars:
      expected: "Should detect risk for duplicate KMS key creation and potential data loss"
    assert:
      # Currently this scenario produces 0 risks
      - type: javascript
        value: |
          const count = parseInt(context.vars.risk_count);
          console.log('kms_orphan_simulation risk count:', count);
          if (count === 0) {
            console.log('WARNING: kms_orphan_simulation produced 0 risks - may be expected for this scenario');
          }
          return true;  // Pass for now
        metric: scenario_check
      # IF risks are detected, check if they're relevant
      - type: javascript
        value: |
          const risksJson = context.vars.risks_json;
          if (!risksJson || risksJson === '[]') {
            console.log('kms_orphan_simulation: No risks detected');
            return true;  // Pass - KMS scenarios may not always trigger risks
          }
          const risks = JSON.parse(risksJson);
          const found = risks.some(r => 
            /kms|encrypt|key|orphan|duplicate|data.?loss/i.test((r.title || '') + ' ' + (r.description || ''))
          );
          console.log('kms_orphan_simulation: Found KMS-related risk:', found);
          return found || risks.length === 0;
        metric: relevant_if_present

  # ===========================================================================
  # GCP: shared_firewall_open
  # ===========================================================================
  - description: "shared_firewall_open: Should detect GCP firewall risk"
    vars:
      expected: "Should detect high/critical risk for GCP firewall open to internet"
    assert:
      - type: javascript
        value: |
          const count = parseInt(context.vars.high_risk_count);
          console.log('High risk count for shared_firewall_open:', count);
          return count > 0;
        metric: has_high_risk
      - type: javascript
        value: |
          const risksJson = context.vars.risks_json;
          if (!risksJson || risksJson === '[]') return false;
          const risks = JSON.parse(risksJson);
          const found = risks.some(r => 
            /firewall|ssh|port.?22|0\.0\.0\.0|internet|gcp|gce/i.test((r.title || '') + ' ' + (r.description || ''))
          );
          console.log('Found firewall-related risk:', found);
          return found;
        metric: mentions_firewall
      - type: llm-rubric
        value: |
          Opening SSH on a GCP firewall to 0.0.0.0/0 is a critical security issue,
          similar to AWS security groups. All instances with the network tag are exposed.
          Score 1 if risks correctly identify firewall/SSH exposure, 0 if not.
        metric: quality_score

  # ===========================================================================
  # GCP: central_pubsub_change
  # ===========================================================================
  - description: "central_pubsub_change: Should detect Pub/Sub IAM risk"
    vars:
      expected: "Should detect risk for central Pub/Sub topic IAM policy change"
    assert:
      - type: javascript
        value: |
          const count = parseInt(context.vars.risk_count);
          console.log('Risk count for central_pubsub_change:', count);
          return count > 0;
        metric: has_risk
      - type: javascript
        value: |
          const risksJson = context.vars.risks_json;
          if (!risksJson || risksJson === '[]') return false;
          const risks = JSON.parse(risksJson);
          const found = risks.some(r => 
            /pub.?sub|topic|iam|policy|messaging|allAuthenticatedUsers/i.test((r.title || '') + ' ' + (r.description || ''))
          );
          console.log('Found pubsub-related risk:', found);
          return found;
        metric: mentions_pubsub
      - type: llm-rubric
        value: |
          Modifying the central Pub/Sub topic IAM policy to add allAuthenticatedUsers 
          is a security risk. All regional subscriptions connect to this topic.
          The assessment should identify the overly permissive access grant.
          Score 1 if the analysis captures this IAM/messaging risk, 0 if not.
        metric: quality_score

  # ===========================================================================
  # GCP: gce_downgrade
  # ===========================================================================
  - description: "gce_downgrade: Should analyze GCE machine type change"
    vars:
      expected: "May or may not flag as risk - machine type downgrade from e2-micro to f1-micro"
    assert:
      - type: javascript
        value: |
          try {
            const risks = JSON.parse(context.vars.risks_json || '[]');
            if (risks.length === 0) return true; // No risks is acceptable for minor downgrade
            return risks.some(r => 
              /machine.?type|gce|compute|instance|downgrade|capacity|performance/i.test((r.title || '') + ' ' + (r.description || ''))
            );
          } catch (e) { return true; }
        metric: relevant_analysis
      - type: llm-rubric
        value: |
          Downgrading GCE machine type from e2-micro to f1-micro is a minor change.
          It may cause slight performance degradation but is not critical.
          If flagged as a risk, it should be low severity. If not flagged, that's acceptable.
          Score 1 if the analysis is proportionate to the actual risk, 0 if overblown.
        metric: quality_score

  # ===========================================================================
  # GCP: function_timeout
  # ===========================================================================
  - description: "function_timeout: Should detect Cloud Function timeout risk"
    vars:
      expected: "Should detect risk for Cloud Function timeout reduced to 1 second"
    assert:
      - type: javascript
        value: |
          const count = parseInt(context.vars.risk_count);
          console.log('Risk count for function_timeout:', count);
          return count > 0;
        metric: has_risk
      - type: javascript
        value: |
          const risksJson = context.vars.risks_json;
          if (!risksJson || risksJson === '[]') return false;
          const risks = JSON.parse(risksJson);
          const found = risks.some(r => 
            /timeout|function|cloud.?function|reliability|1.?second/i.test((r.title || '') + ' ' + (r.description || ''))
          );
          console.log('Found timeout-related risk:', found);
          return found;
        metric: mentions_timeout
      - type: llm-rubric
        value: |
          Reducing Cloud Function timeout from 60s to 1s will cause widespread failures.
          Most function operations cannot complete in 1 second.
          Score 1 if risks identify this reliability concern, 0 if not.
        metric: quality_score

  # ===========================================================================
  # GCP: combined_gcp_all
  # ===========================================================================
  - description: "combined_gcp_all: Should detect multiple GCP risks"
    vars:
      expected: "Should detect multiple risks for combined GCP changes"
    assert:
      - type: javascript
        value: |
          const count = parseInt(context.vars.high_risk_count);
          console.log('High risk count for combined_gcp_all:', count);
          return count > 0;
        metric: has_high_risk
      - type: javascript
        value: |
          const count = parseInt(context.vars.risk_count);
          console.log('Total risk count for combined_gcp_all:', count);
          return count >= 1;
        metric: multiple_risks
      - type: llm-rubric
        value: |
          The combined_gcp_all scenario includes firewall open to internet and 
          Pub/Sub IAM changes. The analysis should identify multiple GCP-specific
          security and access control risks.
          Score 1 if multiple risks are identified with appropriate severity, 0 if not.
        metric: quality_score
